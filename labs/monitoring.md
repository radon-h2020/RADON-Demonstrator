# Monitoring Tool


> The Monitoring Tool offers the capability to monitor serverless functions and obtain monitoring metrics through the automatic creation of personalized, user-proprietary Monitoring dashboards. This is feasible by the deployment of a Push Gateway node and the definition of an AWSISMonitoredBy relationship, provided by the Monitoring tool.


# Overview


Initially, the function code has to be injected with a code snippet through which the metrics are pushed towards the Prometheus Push Gateway instance. Since the serverless function is hosted on a nodeJS runtime environment, the code snippet is triggering a parallel worker thread to push metrics parallel to the execution of the cloud function. Monitored metrics are collected by PushGateway. 

Finally through the defintion of the AWSISMonitoredBy relationship, user proprietary Grafana dashboards are created and the monitoring metrics collected by the Prometheus PushgateWay node are visualized towards the user.

![](https://i.ibb.co/ccjmC1M/Screenshot-2021-06-18-at-1-37-46-PM.png)



# Detailed Steps


- Set up the nodes

In order to integrate the monitoring tool to the ServerelessToDoAPI, the user has to initially create an EC2 instance. This EC2 instance will host a Docker Engine node which subsequently will host the Pushgateway Node. In addition the Pushgateway node has to depend on the EC2 to get an ip dynamically. The above mentioned 3 nodes are needed to deploy the monitoring tools. In detail:

![](https://i.ibb.co/0VTDPYP/Screenshot-2021-06-18-at-1-43-07-PM.png)

Additionally, the Push Gateway node has to be configured with the following information:

![](https://i.ibb.co/Q82ksgp/Screenshot-2021-06-18-at-1-45-13-PM.png)


- Setup the monitoring relationships

Apart from the above mentioned relationships, for every function to be monitored the user has to configure the AWSIsMonitoredBy/GCPIsMonitoredBy relationships between the function and the Pushgateway Node (newly added capability monitor in pushgateway). Hence the Monitoring tool is configured to receive metrics from the function.

![](https://i.ibb.co/S7ymy1R/Screenshot-2021-06-18-at-1-47-56-PM.png)

This relationship through its configuration scripts takes care of all the steps. No additional configuration is required. 


- Inject the function code

As stated in the beginning, for the monitoring to be feasible the function code has to be code injected or wrapped depending on the function runtime.
Since in ServerelessToDoAPI the functions are implemented in Node runtime(single thread operations), the function codes have to be wrapped with service workers to expose these metrics towards Pushgateway. The acquired metris are RAM and CPU.

![](https://i.ibb.co/zXmKvL2/Screenshot-2021-06-18-at-1-50-40-PM.png)

The code that wraps a Node JS application can be found here: 
https://github.com/radon-h2020/radon-monitoring-tool/blob/master/lambda/nodejs-runtime/toDoGet-nodeJS-monitored-function.zip
In the link above, the toDoGet cloud function is wrapped to expose the RAM and CPU metrics


- Deploy the tosca model

OPERA_SSH_USER=ubuntu OPERA_SSH_IDENTITY_FILE=/tmp/{{your key}}.pem opera deploy --clean-state {{path to tosca file}}.tosca


- Access the Dashboards

Log in http://3.127.254.144:3000 using your keycloak credentials. Once the user is logged in the relevant dashboards are available. The dashboards are user proprietary and can be accessed only on the provided email account.


- Invoke the functions

After function invocation the Grafana dashboards are updated in real time. The user can see the function performance metrics.


- Trigger Alerting and Scaling Capabilities

By invoking the Node Policy definition mechanism along with an xOpera SaaS-adapted way of deployment, the Monitoring Tool can be extended to generate Alarms and trigger scaling events towards xOpera SaaS. Eventually, every serverless function can be assigned with one or more scaling policies. In these policies, the user can define thresholds and adjustments to resources (RAM, CPU) whenever these thresholds are violated. 
In GMT, the following policy is attached to a Lambda function and is used to generate an alert every time the RAM monitored metrics exceed 80 % of the total capacity.

![](https://i.ibb.co/NNVZwmV/Screenshot-2021-06-18-at-1-53-56-PM.png)

In the service template, the policy is attached to the Lambda function.

![](https://i.ibb.co/mcYpqhH/Screenshot-2021-06-18-at-1-55-21-PM.png)

A callback url has to be provided per scaling event. This url is generated by the user in the xOpera SaaS prior to the deployment.

![](https://i.ibb.co/rchF8FT/Screenshot-2021-06-18-at-1-56-07-PM.png)

The callback url is provided through the inputs.yml file.

![](https://i.ibb.co/ww4FvYR/Screenshot-2021-06-18-at-1-57-09-PM.png)

The alert will be forwarded to xOpera SaaS which subsequently will trigger the execution of a scale action .yml file. 

![](https://i.ibb.co/V9bPFxj/Screenshot-2021-06-18-at-1-58-29-PM.png)

Hence through the execution of this playbook the RAM of the monitored Lambda function will be increased according to the adjustment (duplicate the value).
After the successful deployment, during the execution phase, whenever there is a threshold violation an alert will be generated by the Grafana API, forwarded to xOpera SaaS, trigger the scaling event and scale up the resources.

